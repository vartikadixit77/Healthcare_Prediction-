{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a05c0587",
   "metadata": {},
   "source": [
    "# Health Care Prediction on Diabetic Patients - Case Study\n",
    "\n",
    "## Context\n",
    "\n",
    "This dataset originates from the National Institute of Diabetes and Digestive and Kidney Diseases. Its primary objective is to diagnostically predict whether a patient has diabetes or not based on specific diagnostic measurements. The dataset was carefully selected, focusing on female patients aged at least 21 years and of Pima Indian heritage.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Build a model with high accuracy to predict whether patients in the dataset have diabetes.\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "The dataset includes various medical predictor variables and one target variable, \"Outcome.\" The predictor variables encompass essential health metrics, such as the number of pregnancies, plasma glucose concentration, diastolic blood pressure, triceps skinfold thickness, insulin levels, body mass index (BMI), diabetes pedigree function, and age.\n",
    "\n",
    "### Predictor Variables\n",
    "\n",
    "1. **Pregnancies:**\n",
    "   - Number of times pregnant\n",
    "\n",
    "2. **Glucose:**\n",
    "   - Plasma glucose concentration at 2 hours in an oral glucose tolerance test\n",
    "\n",
    "3. **BloodPressure:**\n",
    "   - Diastolic blood pressure (mm Hg)\n",
    "\n",
    "4. **SkinThickness:**\n",
    "   - Triceps skinfold thickness (mm)\n",
    "\n",
    "5. **Insulin:**\n",
    "   - 2-Hour serum insulin (mu U/ml)\n",
    "\n",
    "6. **BMI:**\n",
    "   - Body mass index (weight in kg/(height in m)^2)\n",
    "\n",
    "7. **DiabetesPedigreeFunction:**\n",
    "   - Diabetes pedigree function : The Diabetes Pedigree Function (DPF) is a mathematical function used to assess the risk of diabetes in individuals based on their family history of the disease.\n",
    "\n",
    "8. **Age:**\n",
    "   - Age in years\n",
    "\n",
    "### Target Variable\n",
    "\n",
    "- **Outcome:**\n",
    "   - Class variable (0 or 1)\n",
    "   - 268 instances are labeled as 1 (indicating diabetes), while others are labeled as 0.\n",
    "\n",
    "This dataset provides a valuable opportunity to develop a predictive model for diabetes based on demographic and health-related features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3418b5",
   "metadata": {},
   "source": [
    "### Loading the required Library Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523b094",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.0' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Admin 11/AppData/Local/Programs/Python/Python313/python3.13t.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error,classification_report,confusion_matrix,precision_score,recall_score,roc_curve,auc\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2495b8e8",
   "metadata": {},
   "source": [
    "### Reading and exploring the Health Care Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f40ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('health care diabetes.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28cb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Information Overview\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16672d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics for the Diabetes Dataset\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992743d",
   "metadata": {},
   "source": [
    "###  Data Preprocessing: Treating the Missing Values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7031b25",
   "metadata": {},
   "source": [
    "### In this datasets 0 represents the null values, and hence we will replace 0 by mean of their feature (variable) columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying the mean of the features\n",
    "print(data['Glucose'].mean())\n",
    "print(data['BloodPressure'].mean())\n",
    "print(data['SkinThickness'].mean())\n",
    "print(data['Insulin'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the number of rows which has the null values\n",
    "print('Glucose-',len(data['Glucose'][data['Glucose']==0]))\n",
    "print('BloodPressure-',len(data['BloodPressure'][data['BloodPressure']==0]))\n",
    "print('SkinThickness-',len(data['SkinThickness'][data['SkinThickness']==0]))\n",
    "print('Insulin-',len(data['Insulin'][data['Insulin']==0]))\n",
    "print('BMI-',len(data['BMI'][data['BMI']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d066525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the null value percentage\n",
    "selected_columns = ['Glucose', 'BloodPressure', 'SkinThickness','Insulin','BMI']\n",
    "null_percentage = (data[selected_columns] == 0).mean() * 100\n",
    "\n",
    "# Displaying the null value percentage for each selected column\n",
    "print(\"Percentage of Null Values for Each Column:\")\n",
    "print(null_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ab217",
   "metadata": {},
   "source": [
    "### Inferences from Null Value Percentage Analysis\n",
    "\n",
    "The analysis of null value percentages in the dataset reveals the following insights:\n",
    "\n",
    "1. **Glucose:**\n",
    "   - Approximately 0.65% of the data points in the \"Glucose\" column are represented as null values.\n",
    "\n",
    "2. **Blood Pressure:**\n",
    "   - The \"Blood Pressure\" column has a null value percentage of approximately 4.56%.\n",
    "\n",
    "3. **Skin Thickness:**\n",
    "   - A significant portion of the \"Skin Thickness\" column, around 29.56%, contains null values.\n",
    "\n",
    "4. **Insulin:**\n",
    "   - The \"Insulin\" column exhibits a higher null value percentage, with approximately 48.70% of the data points being null.\n",
    "\n",
    "These findings suggest that imputation or other strategies may be necessary for columns with substantial null values, such as \"Skin Thickness\" and \"Insulin,\" to ensure the integrity of the dataset for subsequent analyses or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the null values with the mean\n",
    "data['Glucose']=data['Glucose'].replace([0],[data['Glucose'].mean()])\n",
    "data['BloodPressure']=data['BloodPressure'].replace([0],[data['BloodPressure'].mean()])\n",
    "data['SkinThickness']=data['SkinThickness'].replace([0],[data['SkinThickness'].mean()])\n",
    "data['Insulin']=data['Insulin'].replace([0],[data['Insulin'].mean()])\n",
    "data['BMI']=data['BMI'].replace([0],[data['BMI'].mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06844c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the null value percentage of the treated columns\n",
    "null_percentage_treated = (data[selected_columns] == 0).mean() * 100\n",
    "\n",
    "# Displaying the null value percentage for each selected column\n",
    "print(\"Percentage of Null Values for Each Column after the null value treatment:\")\n",
    "print(null_percentage_treated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e7a517",
   "metadata": {},
   "source": [
    "### Inference from Null Value Treatment\n",
    "\n",
    "After addressing null values in the dataset, it is observed that all selected columns (\"Glucose,\" \"Blood Pressure,\" \"Skin Thickness,\" and \"Insulin\") no longer contain any null values. The null value treatment has been successful, resulting in a clean dataset with 0% null values in these specific columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db07a6a",
   "metadata": {},
   "source": [
    "## Detecting Outliers and Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff42b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=data[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdbbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display boxplots for numeric columns to visualize outliers\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=columns)\n",
    "plt.title(\"Boxplots for Numeric Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a45d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbc8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the Outlier Count in the selected Columns:\n",
    "def find_outliers_iqr(data, column_name):\n",
    "    # Calculate the first quartile (Q1) and third quartile (Q3)\n",
    "    Q1 = data[column_name].quantile(0.25)\n",
    "    Q3 = data[column_name].quantile(0.75)\n",
    "\n",
    "    # Calculate the interquartile range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Find outliers\n",
    "    outliers = data[(data[column_name] < lower_bound) | (data[column_name] > upper_bound)]\n",
    "\n",
    "    # Count the number of outliers\n",
    "    count_outliers = len(outliers)\n",
    "\n",
    "    return count_outliers\n",
    "\n",
    "# Calculate and print the number of outliers for each column of interest\n",
    "for column_name in selected_columns:\n",
    "    outlier_count = find_outliers_iqr(data, column_name)\n",
    "    print(f\"Number of outliers in the '{column_name}' column: {outlier_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b517a631",
   "metadata": {},
   "source": [
    "### Boxplot Analysis for Numerical Columns\n",
    "\n",
    "The boxplot illustrates the distribution of four numerical columns: Glucose, BloodPressure, Skin Thickness, and Insulin. The following inferences can be drawn:\n",
    "\n",
    "#### Glucose\n",
    "- Median glucose level: ~200 mg/dL\n",
    "- IQR is large, indicating considerable variability in glucose levels.\n",
    "- There are no outliers\n",
    "\n",
    "#### Blood Pressure\n",
    "- Median blood pressure: 72 mmHg (within the normal range).\n",
    "- IQR is relatively small, suggesting more consistent blood pressure levels.\n",
    "- Few outliers, none extremely high or low.\n",
    "\n",
    "#### Skin Thickness\n",
    "- Median skin thickness: ~25 mm\n",
    "- IQR is small, indicating less considerable variability in skin thickness.\n",
    "- Few outliers, none extremely high.\n",
    "\n",
    "#### Insulin\n",
    "- Median insulin level: ~79 mIU/L\n",
    "- IQR is large, indicating considerable variability in insulin levels.\n",
    "- More outliers, many are extremely high.\n",
    "\n",
    "#### Overall Observations\n",
    "- All columns exhibit a wide range of values, with some outliers. Insulin column has many outliers\n",
    "- Median values for all columns, except the insulin column fall within the normal range.\n",
    "\n",
    "#### Additional Inferences\n",
    "- Glucose levels show more variability than blood pressure levels.\n",
    "- More outliers in the insulin columns compared to blood pressure and skin thickness.\n",
    "\n",
    "#### Possible Interpretations\n",
    "- Variability in glucose levels may be influenced by factors like diet, exercise, and stress.\n",
    "- Outliers in the Insulin column may also be associated with underlying medical conditions or physiological factors. Elevated insulin levels could be indicative of conditions such as insulin resistance or diabetes. Additionally, factors such as dietary habits, genetic predisposition, or specific medical treatments may contribute to higher insulin levels. Further investigation and domain expertise are necessary to understand the potential health implications of these outliers in the Insulin column. \n",
    "\n",
    "It is essential to note that these inferences are based on a single boxplot, and further information is needed to draw definitive conclusions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3922a3ad",
   "metadata": {},
   "source": [
    "## Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f08def",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(data)\n",
    "Q1=data.quantile(0.20)\n",
    "Q3=data.quantile(0.80)\n",
    "IQR=Q3-Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleared_iqr = data[~((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "data_cleared_iqr\n",
    "print(data_cleared_iqr.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleared_iqr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b52c6df",
   "metadata": {},
   "source": [
    "### Inferences from Outlier Removal using IQR Method\n",
    "\n",
    "1. **Data Size Reduction:**\n",
    "   - After removing outliers using the interquartile range (IQR) method, the dataset has been reduced from 768 to 678 rows.\n",
    "\n",
    "2. **Outliers Identified:**\n",
    "   - Outliers were detected and removed across various columns, particularly impacting features like Glucose, Blood Pressure, Skin Thickness, Insulin, BMI, and Age.\n",
    "\n",
    "3. **Increased Data Robustness:**\n",
    "   - The IQR-based outlier removal contributes to a more robust dataset, potentially improving the reliability of statistical analyses and modeling.\n",
    "\n",
    "4. **Preserved Features:**\n",
    "   - The operation was applied to 9 columns, including predictors like Glucose and Skin Thickness, as well as the target variable Outcome.\n",
    "\n",
    "5. **Consideration for Domain Knowledge:**\n",
    "   - The decision to remove outliers should be made with consideration for domain knowledge, as outliers may contain valuable information or indicate specific health conditions.\n",
    "\n",
    "**Final Dataset Statistics:**\n",
    "- Dataset size after outlier removal: 678 rows.\n",
    "- Original dataset size: 768 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2962d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=data_cleared_iqr[['Glucose','BloodPressure','SkinThickness','Insulin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the outliers after treatment using box plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7575ab8",
   "metadata": {},
   "source": [
    "#### It can be observed that the outliers have been significantly reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea321e3",
   "metadata": {},
   "source": [
    "## EDA - Univariate analysis for each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a643a94",
   "metadata": {},
   "source": [
    "### Visually exploring variables using histograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f468bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Glucose'].plot(kind='hist',figsize=(10,5))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d92012",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BloodPressure'].plot(kind='hist',figsize=(10,5))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036761e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SkinThickness'].plot(kind='hist',figsize=(10,5),)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b742f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Insulin'].plot(kind='hist',figsize=(10,5))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda9181d",
   "metadata": {},
   "source": [
    "### Violin plot for the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f265f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.violinplot(data=data[selected_columns])\n",
    "plt.title(\"Violin Plot of Selected Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b0540",
   "metadata": {},
   "source": [
    "#### The violin plot shows the distribution of four numerical features: Glucose, BloodPressure, Skin Thickness, and Insulin. The violin shape represents the probability density function (PDF) of each feature, and the box plot embedded within each violin plot shows the median, interquartile range (IQR), and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78640d83",
   "metadata": {},
   "source": [
    "###  Kernel Density Estimation (KDE) plot for the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ceca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for column in selected_columns:\n",
    "    sns.kdeplot(data[column], label=column)\n",
    "plt.title(\"Kernel Density Estimation (KDE) Plot of Numeric Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd900d",
   "metadata": {},
   "source": [
    "#### The image shows a Kernel Density Estimation (KDE) plot of four numerical features: Glucose, BloodPressure, Skin Thickness, and Insulin. KDE is a non-parametric method for estimating the probability density function (PDF) of a random variable. The KDE plot shows the estimated PDF of each feature, which can be used to visualize the distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f43cb87",
   "metadata": {},
   "source": [
    "###  Creating a count (frequency) plot describing the data types and the count of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ad2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(16,2)\n",
    "data.dtypes.value_counts().plot(kind='barh')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80440962",
   "metadata": {},
   "source": [
    "#### It can be Observed that there are three features of integer data type and six features of float data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a995924",
   "metadata": {},
   "source": [
    "### Data Exploration:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e2eb3",
   "metadata": {},
   "source": [
    "### Check the balance of the data by plotting the count of outcomes by their value. Describe your findings and plan future course of action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68bc632",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Outcome'].value_counts().plot(kind='bar')\n",
    "plt.legend()\n",
    "plt.title('Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome=(data['Outcome'].value_counts()/data['Outcome'].shape)*100\n",
    "outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339d0ca4",
   "metadata": {},
   "source": [
    "### Inferences from Outcome Distribution\n",
    "\n",
    "1. **Class Imbalance:**\n",
    "   - The dataset exhibits class imbalance in the 'Outcome' variable.\n",
    "   - Class 0 (No Diabetes) has 500 instances.\n",
    "   - Class 1 (Diabetes) has 268 instances.\n",
    "\n",
    "2. **Potential Impact on Modeling:**\n",
    "   - Class imbalances may affect the performance of machine learning models, particularly for binary classification tasks.\n",
    "   - Addressing class imbalance through techniques like resampling or using appropriate evaluation metrics may be necessary.\n",
    "\n",
    "3. **Consideration for Predictive Models:**\n",
    "   - Models may need to be evaluated and tuned considering the imbalanced distribution to avoid biased predictions toward the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8643129",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data=100-outcome\n",
    "balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data.plot(kind='bar')\n",
    "plt.legend()\n",
    "plt.title('Balanced_data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed78a9",
   "metadata": {},
   "source": [
    "###  Findings and plan future course of action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a2848",
   "metadata": {},
   "source": [
    " - We can see It's a Imbalance dataset,This shows that a dataset is biased towards a class(0) in the dataset. If the dataset is biased towards one class, an algorithm trained on the same data will be biased towards the same class,so first we have to balance it.\n",
    " - We can use Resampling or SMOTE to balance a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef3648",
   "metadata": {},
   "source": [
    "### Bi-Variate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9cb6fe",
   "metadata": {},
   "source": [
    "###  Creating scatter charts between the pair of variables to understand the relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318c806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.scatterplot(x='Glucose',y='BloodPressure',hue='Outcome',data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8489aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.scatterplot(x='BMI',y='Insulin',hue='Outcome',data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768a7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x='SkinThickness',y='Insulin',hue='Outcome',data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49539355",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x='Age',y='Glucose',hue='Outcome',data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8feba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x='Age',y='Pregnancies',hue='Outcome',data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a224ec",
   "metadata": {},
   "source": [
    "- We can see Pregnancies has highest relation with Age feature.\n",
    "- Also, Outcome has maximum relation with Glucose and minimum with Blood Presure than the other features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a4514",
   "metadata": {},
   "source": [
    "- We can see from scatter plot, that there is ouliers present in this data.\n",
    "- Because of outliers, our data is skewed to left or right side, which is not acceptable.\n",
    "- If we want to train a model, this poses a problem.\n",
    "- Therefore, for better visualization and outlier detection, we can use sns.boxplot and remove outliers from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e447f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)\n",
    "plt.suptitle(\"Pairplot of Numeric Features\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63515a7",
   "metadata": {},
   "source": [
    "### Multi-Variate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be61569",
   "metadata": {},
   "source": [
    "### Perform correlation analysis. Visually explore it using a heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(data.corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb46ad78",
   "metadata": {},
   "source": [
    "#### We can see Outcome has maximum relation with Glucose and minimum with Blood Presure than the other features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e990e3",
   "metadata": {},
   "source": [
    "## Data Modeling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de4db6",
   "metadata": {},
   "source": [
    "###  1- Devise strategies for model building. It is important to decide the right validation framework. Express your thought process. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e6bda5c",
   "metadata": {},
   "source": [
    "strategies for model building :-\n",
    "    \n",
    "    1. Descriptive Analysis :-\n",
    "        -Identify ID, Input and Target features\n",
    "        -Identify categorical and numerical features\n",
    "        -Identify columns with missing values\n",
    "        \n",
    "    2. Data Treatment (Missing values treatment) :-\n",
    "        - Detecting outliers & removing them. \n",
    "        - Imputing mean, mode or median value at a place of missing value as per dataset   \n",
    "        \n",
    "    3.Feature Extraction / Feature Engineering :-\n",
    "        -we will remove noisy features from data\n",
    "        -By the help of correlation / heatmap / differnt types of feature selection techniques.\n",
    "        \n",
    "    4.Data is imbalanced\n",
    "        -For balancing the data we wil use SMOTE over sampling techinque.\n",
    "        \n",
    "    5.Building a model :-\n",
    "        - select a best algorithms for model\n",
    "        \n",
    "    6.Train a model\n",
    "    \n",
    "    7.Evaluation\n",
    "        - check a accuracy & mean squared error of model\n",
    "        \n",
    "    8.Hyper Parameter Tunning :-\n",
    "        -for decrese in RMSE check a best parameters for model.\n",
    "        \n",
    "    9.Create a clasification report.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbffea4",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation for Modeling\n",
    "x=data.drop(['Outcome'],axis=1)\n",
    "y=data.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1762963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the Correlation of every feature with the Outcome (Target Variable)\n",
    "data.corrwith(data['Outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfeatures = SelectKBest(score_func=chi2, k='all')\n",
    "fit = bestfeatures.fit(x,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(x.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(8,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60da827",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(data.corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c9ac963",
   "metadata": {},
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model.fit(x,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=x.columns)\n",
    "feat_importances.nlargest(8).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee1da2",
   "metadata": {},
   "source": [
    "- We can see BloodPressure features has lowest relation with output column.\n",
    "- So we will remove BloodPressure for training a good model with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a5c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x=data.drop(['Outcome','BloodPressure'],axis=1).values\n",
    "new_y=data.Outcome.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a96ce",
   "metadata": {},
   "source": [
    "### SMOTE to address the Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fbfbd9",
   "metadata": {},
   "source": [
    "### Train a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d69085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split for Data Modeling\n",
    "trainx,testx,trainy,testy=train_test_split(new_x,new_y,test_size=0.20,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ec561",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(trainy == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(trainy == 0)))\n",
    "  \n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state =63)\n",
    "trainx_res,trainy_res = sm.fit_resample(trainx,trainy.ravel())  \n",
    "print('After OverSampling, the shape of train_X: {}'.format(trainx_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(trainy_res.shape))\n",
    "  \n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(trainy_res == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(trainy_res == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e2c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71cac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainx=sc.fit_transform(trainx)\n",
    "#testx=sc.fit_transform(testx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ecb14",
   "metadata": {},
   "source": [
    "## Applying an appropriate classification algorithm to build a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f22d4",
   "metadata": {},
   "source": [
    "## Model 1: Building a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(solver='liblinear',random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1703c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(trainx_res,trainy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=logreg.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd8251",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy_score -',accuracy_score(testy,prediction))\n",
    "print('Mean_squared_error -',mean_squared_error(testy,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67572766",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((confusion_matrix(testy,prediction)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd889e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testy,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ff4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing ROC Curve (Receiver Operating Characteristics Curve)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predict probabilities\n",
    "probs = logreg.predict_proba(trainx_res)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(trainy_res, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(trainy_res, probs)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf99042",
   "metadata": {},
   "source": [
    "## Model 2: RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07bef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(random_state=42,max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(trainx_res,trainy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predict=rf.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150f4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy_score -',accuracy_score(testy,rf_predict))\n",
    "print('Mean_squared_error -',mean_squared_error(testy,rf_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e5895",
   "metadata": {},
   "source": [
    "### RandomForestClassifier( Hyper Parameter Tuning )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'n_estimators':[100,400,200,300],'criterion':['gini','entropy'],'max_depth':[1,2,3],'min_samples_split':[2,4,3],'min_samples_leaf':[1,2,3],\n",
    "'max_leaf_nodes':[1,2,3],'max_samples':[2,4,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd286cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV( estimator=rf,param_grid=param_grid,n_jobs=-1,cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid.fit(trainx_res,trainy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid=RandomForestClassifier(criterion= 'gini',max_depth= 2,max_leaf_nodes=3,max_samples=4,min_samples_leaf= 1,min_samples_split=3,\n",
    " n_estimators= 400,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed204f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid.fit(trainx_res,trainy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_predict=rf_grid.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b77498",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy_score -',accuracy_score(testy,rf_grid_predict))\n",
    "print('Mean_squared_error -',mean_squared_error(testy,rf_grid_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ace38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((confusion_matrix(testy,prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testy,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d0de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing ROC Curve (Receiver Operating Characteristics Curve)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predict probabilities\n",
    "probs = rf.predict_proba(trainx_res)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(trainy_res, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(trainy_res, probs)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d432a",
   "metadata": {},
   "source": [
    "## Model 3: DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc=DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f729a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.fit(trainx_res,trainy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31786133",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_pred=dc.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy_score -',accuracy_score(testy,dc_pred))\n",
    "print('Mean_squared_error -',mean_squared_error(testy,dc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c2f586",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier( Hyper Parameter Tunning )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_param_grid={'splitter':[\"best\", \"random\"],'criterion':['gini','entropy'],'max_depth':[1,2,3],\n",
    "'min_samples_split':[1,2,3],'min_samples_leaf':[1,2,3],'max_leaf_nodes':[1,2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236fe79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "dc_grid=GridSearchCV(estimator=dc,param_grid=dc_param_grid,n_jobs=-1,cv=5,verbose=2)\n",
    "dc_grid.fit(trainx_res,trainy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fcc67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_final=DecisionTreeClassifier(criterion= 'gini', max_depth=2,max_leaf_nodes=4,min_samples_leaf= 1,\n",
    "min_samples_split= 2,splitter='best',random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcce31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_final.fit(trainx_res,trainy_res)\n",
    "dc_final_pred=dc_final.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b359606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy_score -',accuracy_score(testy,dc_final_pred))\n",
    "print('Mean_squared_error -',mean_squared_error(testy,dc_final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((confusion_matrix(testy,dc_final_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e62e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((classification_report(testy,dc_final_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d83d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing ROC Curve (Receiver Operating Characteristics Curve)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predict probabilities\n",
    "probs = dc_final.predict_proba(trainx_res)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(trainy_res, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(trainy_res, probs)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76fc5a0",
   "metadata": {},
   "source": [
    "## Model Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3492b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithms=['RandomForest','Decisiontree']\n",
    "Accuracy_Score=[accuracy_score(testy,rf_grid_predict),accuracy_score(testy,dc_final_pred)]\n",
    "# Create a DataFrame\n",
    "accuracy_df = pd.DataFrame({'Algorithm': Algorithms, 'Accuracy': Accuracy_Score})\n",
    "\n",
    "# Display the accuracy table\n",
    "print(accuracy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1709faff",
   "metadata": {},
   "source": [
    "### Inferences from Model Accuracy Comparison\n",
    "\n",
    "1. **RandomForest Performs Well:**\n",
    "   - Among the algorithms tested, RandomForest exhibits the highest accuracy at 73.38%.\n",
    "\n",
    "2. **Consideration for Model Selection:**\n",
    "   - The choice of the algorithm depends on various factors, including the specific requirements of the task, interpretability, and computational efficiency.\n",
    "\n",
    "3. **Further Evaluation:**\n",
    "   - Additional evaluation metrics, such as precision, recall, and F1 score, should be considered for a comprehensive assessment of model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
